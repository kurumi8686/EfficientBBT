# Advanced Black-Box Tuning of Large Language Models with Limited API Calls

This repository contains the official implementation for the paper  
**"Advanced Black-Box Tuning of Large Language Models with Limited API Calls" (AAAI 2026, Oral)**.

![Overview Figure](./method-flowchart.png)

---

## ðŸ§© Repository Structure

- **`config.py`** â€“ Contains all configuration parameters for experiments.  
- **`utils.py`** â€“ Includes common utility functions used across experiments.  
- **`script.py`** â€“ Run this script to reproduce the full set of experiments reported in the paper.  
- **`black-mock-script.py`** â€“ Run this script to simulate *real-world black-box fine-tuning* scenarios.  
  Please make sure to modify the model paths and other parameters according to your setup.

---

## ðŸ§  Experimental Findings

Our experiments demonstrate that **proxy-based black-box tuning** methods, built upon supervised fine-tuned (SFT) proxy models, significantly enhance the performance of large black-box models on most tasks.  
However, for *complex mathematical reasoning* tasks, the improvement remains limited â€” mainly due to the constrained reasoning capabilities of the smaller proxy model.  

We plan to explore **RL-based proxy-tuning** in future work to overcome this limitation.

---

## ðŸ“¬ Contact

If you have any questions or suggestions regarding the code, feel free to reach out:  
ðŸ“§ **22307110187@m.fudan.edu.cn**

---

> Â© 2025 Fudan University IMC Lab. All rights reserved.
